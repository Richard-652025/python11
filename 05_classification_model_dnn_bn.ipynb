{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665247c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x25ADF640E60>, 9)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+tbw1oNx4m8QWmkWx2yXD4LkZCADJJ+gFbviL4a63oc7COE3MW4hdn38duD976jNc9daDqllIsc9lKrMu4YGeMkdR7gj8KzcV7H8BtEvV16+1iWCeG1Wz8mOV02pIzupwCeuAp6Z98cZ90aIzLIlw0c0ZJ4KgjHoeOa+evjS9n/wnMcNxBPCYLKONFhA2FNzMpGenDcgd816V4K03wefC+m3NlpVhP+5QSXBiR5fMx825iMg5zwce3FdbOzTwgW90lu6uCm8eYrL02soIyCPQgggEdMGQ3cluiPNK0rJwrRQBNueuMkt+teNfGKxsdY8WWdxNqcNo66eieXMwVsb5DnH415Hp2rajpE5n02/urOUjBe3laMkehIPIrVm8eeLrhNknibVivoLtx/I1UPinxC3XXtUP1vJP8ay5JZJpGkldnduSzHJP41//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACD0lEQVR4AbWRz2sTQRTH38zszm42k6Q2TU2ixURstRdRasWC9FCsUE9SpIKnKl48+x94UOjNiyf/h4KgKN7TYgNKK+agjZS0wZDYbND90dn54VqxIWfxXebBB97nfecB/P9CAKkFAGT8ViEEh+9fLZZn7gde+E4AwkgAGYBEzl3btZz55y0tgSl/AHKYLhH85uJKdat2ebqyFmuOCun5laFIwcYXjvLRxq1nfRh3er0ESHAI1fvPYqF8oj9WxxO6hcAyWZhQV2fw6OvBbcEh2O/tlxTCjlRjgPtGAqwYcpN7GWUlPbppXepDTeB2AduQHONWpOzsi09GHxocPobUccZPh8RhcvfOy/V4IUQwigMIgFdeQHWb2BFEipzvxU6iBT9QALNPq8F3oYTnSRt8oN4iHOYcLk4UFs+GOEo0TZrlToXNqp7ZmkQw8yg3JIkrHI6C2lI1dawE9dQPP8HSDiJrRSF9IAFAZmT5+oNm+LU+nuVmispT6N6TbcYsMDONZg7nb9rl5NQU5pgCMq8YrUY6bDCa3t9hQShWt0rD3I0kNxWiE8aebiRH3E7bsEw7hTuTXqNrdSIRJfK9C8aH1bvNesioTcmB1P43JY2QcdeNRLkVR7nx8HjblYQaBGnTpCYC1AKq8ptLCMf55x6PZjAxJGrpPfWTgI58/LZW+fMJ8WXO5bond/j20Y3+sfkFaCTYdrBYeB0AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from deeplearning_train import EarlyStopping, ModelSaver,train_classification_model,plot_learning_curves\n",
    "from deeplearning_train import evaluate_classification_model as evaluate_model\n",
    "\n",
    "\n",
    "# 加载Fashion MNIST数据集，张量就是和numpy数组一样\n",
    "transform = transforms.Compose([])\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "print(train_dataset[0])\n",
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82667c97",
   "metadata": {},
   "source": [
    "# 加载数据并处理为tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18235b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集形状: (60000, 28, 28)\n",
      "训练集标签数量: 60000\n",
      "测试集形状: (10000, 28, 28)\n",
      "测试集标签数量: 10000\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
      "    0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
      "   54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
      "  144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
      "  107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
      "  216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
      "  223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
      "  235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
      "  180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
      "  169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
      "  198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
      "  232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
      "  222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
      "  211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
      "  224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
      "  255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
      "  188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
      "  168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
      "  239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
      "  199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
      "  195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
      "  210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
      "  182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载Fashion MNIST数据集，张量就是和numpy数组一样\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.286,), (0.353,))  \n",
    "])\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 获取图像和标签\n",
    "# 注意：由于使用了transform，图像已经被转换为张量且标准化\n",
    "# 我们需要从dataset中提取原始图像用于显示\n",
    "train_images = train_dataset.data.numpy()\n",
    "train_labels = train_dataset.targets.numpy()\n",
    "test_images = test_dataset.data.numpy()\n",
    "test_labels = test_dataset.targets.numpy()\n",
    "\n",
    "# 定义类别名称\n",
    "class_names = ['T-shirt/top', '裤子', '套头衫', '连衣裙', '外套',\n",
    "               '凉鞋', '衬衫', '运动鞋', '包', '短靴']\n",
    "\n",
    "# 查看数据集基本信息\n",
    "print(f\"训练集形状: {train_images.shape}\")\n",
    "print(f\"训练集标签数量: {len(train_labels)}\")\n",
    "print(f\"测试集形状: {test_images.shape}\")\n",
    "print(f\"测试集标签数量: {len(test_labels)}\")\n",
    "\n",
    "print(train_images[0])\n",
    "\n",
    "train_labels[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d73c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(train_dataset):\n",
    "    # 首先将所有图像堆叠为一个大张量\n",
    "    all_images=torch.stack([image_tensor for image_tensor,_ in train_dataset])\n",
    "    print(all_images.shape)\n",
    "    # 计算通道维度上的均值和标准差\n",
    "    # Fashion MNIST 是灰度图像，只有一个通道\n",
    "    # 对所有像素值计算均值和标准差\n",
    "    mean=torch.mean(all_images)\n",
    "    std=torch.std(all_images)\n",
    "    print(f\"训练数据集均值: {mean.item():.4f}\")\n",
    "    print(f\"训练数据集标准差: {std.item():.4f}\")\n",
    "\n",
    "    # 检查数据集大小\n",
    "    print(f\"数据集中图像总数: {len(train_dataset)}\")\n",
    "\n",
    "# calculate_mean_std(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e40b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a0068",
   "metadata": {},
   "source": [
    "# 把数据集划分为训练集55000和验证集5000，并给DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "455215a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 55000\n",
      "验证集大小: 5000\n",
      "测试集大小: 10000\n",
      "批次大小: 64\n",
      "训练批次数: 860\n"
     ]
    }
   ],
   "source": [
    "# 从训练集中划分出验证集\n",
    "train_size = 55000\n",
    "val_size = 5000\n",
    "# 设置随机种子以确保每次得到相同的随机划分结果\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_subset, val_subset = torch.utils.data.random_split(\n",
    "    train_dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=generator #设置随机种子，确保每次得到相同的随机划分结果\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True #打乱数据集，每次迭代时，数据集的顺序都会被打乱\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 打印数据集大小信息\n",
    "print(f\"训练集大小: {len(train_subset)}\")\n",
    "print(f\"验证集大小: {len(val_subset)}\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")\n",
    "print(f\"批次大小: {batch_size}\")\n",
    "print(f\"训练批次数: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a93d4d",
   "metadata": {},
   "source": [
    "# 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab82393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "m=nn.BatchNorm1d(100)\n",
    "x=torch.randn(20,100)\n",
    "print(m(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dcf3fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, layers_num=3, dropout_rate=0.3, initial_size=512):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # 使用BatchNorm提高模型稳定性和训练速度\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, initial_size),\n",
    "            nn.BatchNorm1d(initial_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "        )\n",
    "        \n",
    "        # 构建漏斗形网络结构，逐层减小神经元数量\n",
    "        current_size = initial_size\n",
    "        for i in range(1, layers_num):\n",
    "            next_size = current_size // 2  # 每层减半\n",
    "            self.linear_relu_stack.add_module(f\"Linear_{i}\", nn.Linear(current_size, next_size))\n",
    "            self.linear_relu_stack.add_module(f\"BatchNorm_{i}\", nn.BatchNorm1d(next_size))\n",
    "            self.linear_relu_stack.add_module(f\"relu_{i}\", nn.ReLU())\n",
    "            self.linear_relu_stack.add_module(f\"dropout_{i}\", nn.Dropout(p=dropout_rate))\n",
    "            current_size = next_size\n",
    "            \n",
    "        # 输出层使用较小的dropout\n",
    "        self.linear_relu_stack.add_module(\"Output_dropout\", nn.Dropout(p=0.1))\n",
    "        self.linear_relu_stack.add_module(\"Output_Layer\", nn.Linear(current_size, 10))\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"使用 xavier 均匀分布来初始化全连接层的权重 W\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # 使用kaiming初始化，更适合ReLU激活函数\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                # 使用小的正数初始化偏置，避免dead ReLU\n",
    "                nn.init.constant_(m.bias, 0.01)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # x.shape [batch size, 1, 28, 28]\n",
    "        x = self.flatten(x)  \n",
    "        # 展平后 x.shape [batch size, 28 * 28]\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        # logits.shape [batch size, 10]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8511a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次图像形状: torch.Size([64, 1, 28, 28])\n",
      "批次标签形状: torch.Size([64])\n",
      "测试图像形状: torch.Size([1, 1, 28, 28])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "模型输出的形状: torch.Size([64, 10])\n",
      "预测结果形状: torch.Size([64])\n",
      "模型预测结果: 0\n",
      "实际标签: 4\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model=NeuralNetwork()\n",
    "\n",
    "# 从train_loader获取第一个批次的数据\n",
    "dataiter=iter(train_loader) # iter()方法返回一个迭代器对象\n",
    "images,labels=next(dataiter) # next()方法返回迭代器的下一个项目\n",
    "\n",
    "# 查看批次数据的形状\n",
    "print(\"批次图像形状:\",images.shape)\n",
    "print(\"批次标签形状:\",labels.shape)\n",
    "\n",
    "# 选择第一张图像进行前向传播测试,unsqueeze(0)是添加批次维度\n",
    "test_image = images[0].unsqueeze(0)  # 添加批次维度\n",
    "print(\"测试图像形状:\", test_image.shape)\n",
    "\n",
    "print('-'*100)\n",
    "\n",
    "with torch.no_grad(): # 禁用梯度计算\n",
    "    outputs=model(images)\n",
    "    print(\"模型输出的形状:\", outputs.shape)\n",
    "\n",
    "# 获取预测结果\n",
    "_, predicted = torch.max(outputs, 1) \n",
    "print(\"预测结果形状:\", predicted.shape)\n",
    "# torch.max()返回的是一个tuple，第一个元素是最大值，第二个元素是最大值的索引,\n",
    "# 第二个参数表示取最大值的方向\n",
    "print(\"模型预测结果:\", predicted[0].item())\n",
    "print(\"实际标签:\", labels[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b797013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总参数量: 569226\n",
      "\n",
      "各层参数量明细:\n",
      "linear_relu_stack.0.weight: 401408 参数\n",
      "linear_relu_stack.0.bias: 512 参数\n",
      "linear_relu_stack.1.weight: 512 参数\n",
      "linear_relu_stack.1.bias: 512 参数\n",
      "linear_relu_stack.Linear_1.weight: 131072 参数\n",
      "linear_relu_stack.Linear_1.bias: 256 参数\n",
      "linear_relu_stack.BatchNorm_1.weight: 256 参数\n",
      "linear_relu_stack.BatchNorm_1.bias: 256 参数\n",
      "linear_relu_stack.Linear_2.weight: 32768 参数\n",
      "linear_relu_stack.Linear_2.bias: 128 参数\n",
      "linear_relu_stack.BatchNorm_2.weight: 128 参数\n",
      "linear_relu_stack.BatchNorm_2.bias: 128 参数\n",
      "linear_relu_stack.Output_Layer.weight: 1280 参数\n",
      "linear_relu_stack.Output_Layer.bias: 10 参数\n"
     ]
    }
   ],
   "source": [
    "# 计算模型的总参数量\n",
    "total_params = sum(p.numel() for p in model.parameters()) # numel() 返回元素数量\n",
    "print(f\"模型总参数量: {total_params}\")\n",
    "\n",
    "# 查看每层参数量明细\n",
    "print(\"\\n各层参数量明细:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} 参数\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61615d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_relu_stack.0.weight',\n",
       "              tensor([[ 0.0689, -0.1150,  0.0815,  ..., -0.0191, -0.0388,  0.0728],\n",
       "                      [ 0.0398, -0.0797, -0.0038,  ...,  0.1411,  0.0053,  0.0623],\n",
       "                      [ 0.0106, -0.0722,  0.0527,  ...,  0.0825, -0.1554,  0.0220],\n",
       "                      ...,\n",
       "                      [ 0.0038, -0.0429, -0.0645,  ..., -0.0503, -0.0414,  0.1806],\n",
       "                      [-0.0362,  0.0727,  0.0980,  ...,  0.1113,  0.0047, -0.0307],\n",
       "                      [-0.0130,  0.0396, -0.0837,  ...,  0.1030,  0.1404,  0.0916]])),\n",
       "             ('linear_relu_stack.0.bias',\n",
       "              tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100])),\n",
       "             ('linear_relu_stack.1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('linear_relu_stack.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('linear_relu_stack.1.running_mean',\n",
       "              tensor([-1.2796e-01,  1.1267e-01,  1.1888e-01, -8.9721e-02, -3.7862e-02,\n",
       "                      -2.8515e-03, -1.9204e-01,  7.5555e-02,  1.4916e-01, -1.4948e-01,\n",
       "                      -5.9608e-02,  1.1204e-01, -3.6428e-02,  9.8894e-02, -1.6770e-02,\n",
       "                      -1.6752e-01,  3.6867e-02,  7.3540e-02, -2.2997e-02,  5.0712e-02,\n",
       "                       1.9553e-02, -3.1933e-02, -3.2664e-02,  6.8794e-02,  4.9692e-03,\n",
       "                      -1.3635e-01, -1.1135e-01, -5.8496e-02, -1.4866e-01,  1.1359e-01,\n",
       "                       6.6773e-02, -5.6194e-02, -4.8225e-02,  1.1933e-01,  2.8685e-02,\n",
       "                       3.3799e-02, -1.3476e-01,  3.2839e-02,  7.3353e-02,  1.4596e-01,\n",
       "                      -2.4968e-01,  2.2429e-03,  1.5046e-02,  1.7906e-01,  5.7123e-02,\n",
       "                      -8.8409e-02,  4.5260e-04,  2.4474e-01, -1.4915e-02, -1.0259e-01,\n",
       "                       4.0964e-02, -1.4037e-02,  7.5305e-02, -1.2336e-01,  2.8027e-02,\n",
       "                      -1.0290e-01,  7.9103e-02, -6.3032e-02, -7.7976e-02,  5.1341e-02,\n",
       "                       3.8329e-02, -2.5221e-02, -8.4200e-02,  1.0514e-01,  5.4015e-02,\n",
       "                       1.1964e-01, -9.3749e-02,  9.2773e-02,  1.1006e-01, -1.3159e-01,\n",
       "                      -1.0538e-01,  1.2569e-01,  3.2074e-02,  3.2567e-03, -5.4094e-02,\n",
       "                       9.3812e-02, -1.2411e-01,  1.8782e-02,  1.0914e-01, -2.4545e-02,\n",
       "                       1.6442e-01,  7.9518e-02,  1.0425e-01,  2.0566e-02,  8.5892e-02,\n",
       "                      -4.8152e-03, -6.9173e-02,  2.0839e-01, -4.6239e-02, -5.4380e-02,\n",
       "                      -4.8542e-02,  8.1058e-02,  9.5825e-02, -7.7188e-03, -7.9689e-02,\n",
       "                       5.7110e-02, -1.3058e-01, -1.9142e-01, -1.6833e-02,  1.0918e-01,\n",
       "                      -1.1315e-01, -4.3313e-02, -2.8266e-02, -5.6719e-02, -1.7677e-01,\n",
       "                      -1.8456e-01, -3.5197e-02,  1.5109e-01,  4.2162e-02, -1.4168e-02,\n",
       "                       3.5367e-02,  2.2382e-02,  2.8547e-02,  8.7799e-02,  1.8545e-01,\n",
       "                      -4.5816e-02, -8.3381e-02,  1.5773e-01, -4.4622e-02, -2.3575e-01,\n",
       "                      -8.9089e-02, -1.8334e-02, -1.1158e-01, -6.2308e-02, -2.6297e-01,\n",
       "                       2.0497e-01, -9.3088e-02, -8.5121e-03, -1.8365e-01, -5.5645e-02,\n",
       "                       9.5157e-02,  2.2491e-01,  1.7337e-02, -5.1975e-02,  1.0870e-01,\n",
       "                       2.2686e-02,  2.2803e-02, -2.1983e-02, -6.2689e-02, -1.9021e-02,\n",
       "                       5.6184e-02,  1.5118e-01, -1.1902e-01,  3.3186e-02,  1.1669e-01,\n",
       "                      -6.2697e-03, -1.5580e-02,  4.6629e-02, -1.2991e-02,  1.4116e-01,\n",
       "                       1.6854e-02, -1.0828e-02, -8.1649e-02,  2.0176e-02, -1.0802e-01,\n",
       "                       3.6082e-03, -6.6496e-02,  2.2100e-02,  2.3387e-01,  3.8448e-02,\n",
       "                       9.4790e-02, -1.6892e-01, -6.6438e-02, -6.4659e-02, -9.5431e-02,\n",
       "                      -4.4010e-02,  4.8104e-02,  5.6950e-02, -6.1760e-02,  3.0403e-02,\n",
       "                      -6.1627e-02, -5.1733e-02,  1.8315e-02,  5.0356e-02, -6.1967e-04,\n",
       "                      -9.6721e-04,  1.9874e-02, -1.2660e-01,  4.7758e-02,  6.1505e-02,\n",
       "                       1.4913e-01, -1.8235e-01, -3.0630e-02, -1.0335e-01,  9.4780e-02,\n",
       "                      -8.6323e-02, -8.1927e-02, -5.7105e-02,  4.6071e-02,  3.3231e-02,\n",
       "                       2.5976e-02, -2.3756e-02, -2.3949e-01, -3.1659e-02, -1.6446e-01,\n",
       "                      -2.4162e-02, -4.3393e-02, -1.8257e-01,  2.5138e-02, -1.5780e-01,\n",
       "                       2.0442e-02, -4.2353e-02, -1.3495e-01,  1.4223e-01, -3.2224e-02,\n",
       "                      -7.4609e-02, -2.5570e-02,  8.0117e-02, -1.7179e-01,  1.9005e-02,\n",
       "                      -6.0579e-03, -8.7846e-02, -1.0091e-01, -3.3846e-02, -1.7775e-01,\n",
       "                      -6.4341e-02, -1.3251e-01,  1.3960e-01, -1.4275e-01, -2.0443e-01,\n",
       "                       1.2314e-01, -2.5555e-02, -4.0573e-02, -1.5931e-01, -7.4491e-02,\n",
       "                      -1.0946e-01, -8.2551e-02, -7.7975e-03, -2.0202e-01, -5.1505e-02,\n",
       "                       2.3668e-03,  1.3517e-01, -6.3952e-02,  1.4580e-01, -1.4208e-02,\n",
       "                       3.7423e-02, -1.0700e-01, -1.5554e-02, -9.3562e-03,  1.1449e-01,\n",
       "                      -3.2812e-02,  8.3280e-03, -1.0044e-01,  2.7721e-04,  6.8465e-02,\n",
       "                      -2.3574e-02,  4.2773e-02, -4.6753e-02,  8.7700e-03,  1.2753e-01,\n",
       "                      -1.0413e-01,  4.5047e-02,  4.5910e-03,  7.9076e-02,  4.1050e-02,\n",
       "                       4.3808e-02,  7.2958e-02,  1.7602e-02,  2.2121e-02,  1.1004e-01,\n",
       "                      -5.3930e-02,  1.4102e-01, -3.8611e-02, -8.9441e-02, -5.8081e-02,\n",
       "                       1.2159e-01, -8.7111e-02,  1.1160e-03,  1.8954e-02, -8.8472e-02,\n",
       "                       2.7646e-02,  1.9923e-02, -4.9920e-02, -2.7843e-02, -1.1730e-01,\n",
       "                      -2.9875e-02, -3.4315e-02,  1.2257e-02, -7.6577e-02,  1.5751e-01,\n",
       "                      -1.9768e-01, -3.3456e-02,  1.0639e-01,  3.7086e-02,  5.9863e-02,\n",
       "                       1.4209e-02,  1.9928e-02, -1.0797e-01,  8.5305e-02,  4.5066e-02,\n",
       "                       3.4811e-02,  6.6656e-02,  1.6957e-01,  5.3329e-02,  1.5124e-02,\n",
       "                       5.8834e-02,  1.0083e-01, -5.7857e-02,  2.3406e-01,  6.7248e-02,\n",
       "                      -1.3527e-01, -1.1470e-01, -5.6756e-02,  1.1326e-01, -2.3312e-01,\n",
       "                       1.7052e-01,  8.4155e-02, -3.5571e-02,  9.0862e-02, -1.8377e-02,\n",
       "                      -1.6747e-01, -1.1867e-01, -6.4903e-02,  5.8048e-02,  7.6362e-02,\n",
       "                      -9.3521e-02,  1.7391e-02, -5.5752e-02,  2.4318e-01,  1.5969e-02,\n",
       "                       9.4747e-02,  1.0638e-01,  1.9613e-02,  2.8612e-01, -2.1037e-02,\n",
       "                      -4.0035e-02, -1.7598e-02, -1.7866e-01,  1.3582e-01,  5.7479e-02,\n",
       "                      -6.4700e-03, -1.3727e-02,  1.3431e-01, -3.9442e-03, -4.3314e-02,\n",
       "                       9.9115e-02, -7.0767e-02,  7.6613e-02,  3.0059e-02,  2.0324e-02,\n",
       "                      -7.1554e-02, -2.7708e-02, -1.4052e-01,  2.7083e-02,  3.4866e-03,\n",
       "                      -5.1934e-02,  2.8567e-01, -8.5811e-02,  1.7587e-03,  1.6523e-01,\n",
       "                      -6.4317e-02, -3.0876e-02,  1.4482e-01,  2.5183e-02,  5.9967e-02,\n",
       "                       1.4395e-02, -1.1039e-01,  4.8151e-02, -2.1780e-01,  8.4197e-02,\n",
       "                       7.4883e-02,  2.5469e-01, -1.2167e-02,  2.7837e-01,  6.2319e-02,\n",
       "                       8.6982e-02, -1.6987e-01, -3.4639e-02,  8.6673e-03,  2.8002e-02,\n",
       "                      -2.1335e-01,  2.5054e-02, -2.5024e-02,  3.2328e-02, -5.9840e-02,\n",
       "                       5.6915e-02, -9.3621e-02, -5.1775e-02,  2.1500e-02, -6.6534e-02,\n",
       "                       1.0423e-01, -3.9176e-02,  6.2087e-02,  1.5525e-01,  2.9615e-03,\n",
       "                      -4.6392e-02,  1.6109e-01, -6.8539e-02, -4.7128e-02, -1.1412e-01,\n",
       "                      -1.3747e-01, -1.4688e-01, -2.1925e-01,  1.4078e-01,  4.6048e-02,\n",
       "                       2.1938e-01,  1.4281e-02,  1.5066e-02,  4.5106e-02, -6.5835e-02,\n",
       "                      -5.4055e-02, -1.3270e-01,  1.0040e-01, -2.2818e-01, -5.5501e-03,\n",
       "                      -3.1140e-02, -1.0971e-01,  6.8513e-02, -9.6113e-02, -4.8628e-02,\n",
       "                       1.1121e-01, -6.6517e-02,  3.9488e-02, -1.4086e-01, -7.8431e-02,\n",
       "                      -1.8463e-01, -8.3542e-02,  1.3061e-01,  1.6854e-01,  3.8779e-02,\n",
       "                      -9.3799e-02,  3.7127e-02,  2.0886e-01, -5.8666e-02,  9.0260e-04,\n",
       "                      -1.1642e-01, -7.1482e-02, -1.5634e-01,  6.9196e-02, -1.2161e-02,\n",
       "                      -1.4879e-04, -1.3078e-02, -3.9581e-02, -1.0012e-01,  9.2941e-02,\n",
       "                      -6.9486e-02, -1.9551e-01, -7.2462e-02, -4.7451e-02,  2.2904e-01,\n",
       "                      -5.9005e-03, -1.5678e-01,  2.6587e-02, -3.7184e-02,  2.0248e-01,\n",
       "                       2.5584e-01,  1.8135e-01, -1.7748e-01, -7.6472e-02,  7.8373e-02,\n",
       "                      -1.4679e-01, -1.2093e-01, -7.9668e-02, -1.7221e-02, -1.3200e-01,\n",
       "                      -6.8421e-02,  1.1837e-02, -1.3067e-01, -1.6030e-01, -1.6856e-01,\n",
       "                      -1.1896e-01, -8.3929e-02,  1.3345e-01, -1.8544e-01, -1.0021e-01,\n",
       "                      -1.3956e-01,  9.1693e-02, -7.6489e-02,  9.8624e-02,  3.8282e-02,\n",
       "                       3.7704e-02, -2.6842e-01,  1.8633e-01, -8.7964e-02,  9.7864e-02,\n",
       "                       1.5197e-01, -1.7257e-01,  1.6062e-01, -9.7476e-02, -4.1145e-02,\n",
       "                       1.6004e-01,  5.3223e-02,  2.2805e-02, -1.0877e-01,  1.3076e-01,\n",
       "                       9.7258e-03, -1.1695e-02,  2.3223e-02, -4.3193e-03,  1.3847e-01,\n",
       "                      -8.6268e-02, -2.1405e-01,  2.7259e-01, -8.7332e-02, -8.1578e-02,\n",
       "                       2.5089e-02, -2.6505e-03,  9.5911e-02,  1.3605e-01,  8.0406e-02,\n",
       "                       1.0558e-02,  1.6886e-01, -4.3329e-02, -1.7338e-01,  2.3256e-01,\n",
       "                       4.4163e-02, -1.0158e-01,  1.2093e-01,  2.3604e-02,  1.6629e-01,\n",
       "                      -2.3671e-01, -3.4168e-02])),\n",
       "             ('linear_relu_stack.1.running_var',\n",
       "              tensor([1.1197, 1.0836, 1.0469, 1.0353, 1.3913, 1.2262, 1.1877, 1.1311, 1.1115,\n",
       "                      1.2477, 0.9893, 1.1717, 1.5649, 1.2181, 1.0411, 1.0148, 1.0352, 1.0778,\n",
       "                      1.0840, 1.1051, 1.0032, 1.0239, 1.0501, 1.2932, 1.1544, 1.1699, 1.0442,\n",
       "                      1.0068, 1.1930, 1.0714, 1.1485, 1.3017, 1.1380, 1.1527, 1.2138, 1.1754,\n",
       "                      1.0124, 1.0085, 1.1620, 1.0504, 1.0223, 1.0398, 1.0858, 1.2332, 1.0953,\n",
       "                      1.1642, 1.0668, 1.1265, 1.1523, 1.1823, 1.0760, 1.0747, 1.0853, 1.2960,\n",
       "                      1.0828, 1.1082, 1.0418, 1.0167, 1.0074, 0.9881, 1.2267, 1.0241, 1.0515,\n",
       "                      1.0826, 1.1891, 1.1084, 1.1207, 1.0311, 1.1015, 1.1248, 1.1092, 1.2112,\n",
       "                      1.2679, 1.1176, 1.2606, 1.1657, 1.1066, 1.1980, 1.1876, 1.0349, 1.1856,\n",
       "                      1.0164, 1.1070, 1.0269, 1.0305, 1.2282, 1.1761, 1.0353, 1.5559, 1.2799,\n",
       "                      1.0409, 1.0604, 1.2342, 1.3419, 1.1171, 1.1316, 1.2690, 1.0513, 1.1358,\n",
       "                      0.9993, 1.0166, 1.2676, 1.2466, 1.2106, 1.1042, 1.3163, 1.0471, 1.2485,\n",
       "                      1.2353, 1.1995, 1.0758, 1.1696, 1.1019, 1.0304, 1.1406, 1.0405, 1.2493,\n",
       "                      1.0836, 1.1130, 1.1712, 1.0508, 1.0833, 1.3362, 1.0304, 1.0992, 1.1364,\n",
       "                      1.1833, 1.0668, 1.1238, 1.1902, 0.9940, 1.0442, 0.9629, 1.3026, 1.5153,\n",
       "                      1.3359, 1.6452, 1.0059, 1.0150, 1.0946, 1.0155, 1.1430, 1.0732, 1.0879,\n",
       "                      1.0158, 1.0254, 1.0593, 1.0745, 1.1409, 1.2363, 1.0677, 0.9903, 1.0450,\n",
       "                      1.1200, 1.0705, 0.9688, 1.4261, 1.1415, 1.0421, 1.0897, 1.0396, 1.0519,\n",
       "                      1.1363, 1.0078, 1.0352, 1.0392, 1.0176, 1.0253, 1.2462, 1.3224, 1.1308,\n",
       "                      1.1697, 1.0338, 1.3133, 1.0414, 1.0417, 1.2086, 1.0983, 1.0854, 1.1846,\n",
       "                      1.0734, 1.1438, 1.2332, 1.0095, 1.2550, 1.0013, 1.0343, 1.0423, 1.0631,\n",
       "                      1.0601, 0.9984, 1.1345, 1.2251, 1.0001, 1.0450, 1.1492, 1.1275, 1.1198,\n",
       "                      0.9752, 1.1371, 1.0395, 1.0629, 1.1415, 1.0879, 1.0360, 1.0839, 1.2821,\n",
       "                      1.6492, 1.3160, 1.3626, 1.2472, 1.8317, 1.2528, 1.0290, 1.1179, 0.9816,\n",
       "                      0.9785, 1.2582, 1.0475, 1.2188, 1.0120, 1.0729, 1.0860, 1.0608, 1.0818,\n",
       "                      1.1145, 1.1974, 1.1805, 1.0919, 1.0580, 1.0091, 1.1452, 1.3092, 1.0635,\n",
       "                      1.0600, 1.2587, 1.0769, 1.0797, 1.1633, 1.0143, 1.0436, 1.1665, 1.0110,\n",
       "                      1.0923, 1.0739, 1.1118, 1.0478, 1.1826, 1.0567, 1.4554, 1.1299, 1.0617,\n",
       "                      1.1266, 1.1721, 1.0276, 1.2538, 1.0652, 1.0183, 1.1073, 1.0009, 1.2555,\n",
       "                      1.1191, 1.0778, 1.0472, 1.1978, 1.0055, 1.0600, 1.0478, 1.0143, 1.0981,\n",
       "                      1.0278, 1.0432, 1.0096, 1.3877, 1.3334, 1.2370, 1.2425, 1.3353, 1.0409,\n",
       "                      1.0626, 1.9713, 1.0278, 1.1863, 1.0031, 1.1985, 1.1603, 1.2043, 1.0671,\n",
       "                      1.0068, 1.0770, 1.2260, 1.1130, 1.1877, 0.9990, 1.0400, 1.1306, 1.0499,\n",
       "                      1.2748, 1.1348, 1.5057, 1.1666, 0.9950, 1.1946, 1.0713, 1.3847, 1.1103,\n",
       "                      0.9859, 1.6273, 0.9956, 1.0290, 1.0698, 1.0684, 1.0860, 1.0032, 0.9894,\n",
       "                      1.0308, 1.0597, 1.0123, 1.0584, 1.1477, 0.9850, 1.2415, 1.0614, 1.4229,\n",
       "                      1.1242, 1.0404, 1.0160, 1.1667, 1.1951, 1.2742, 1.0611, 1.0652, 1.1776,\n",
       "                      1.1541, 1.0881, 1.0083, 0.9985, 1.1199, 1.3040, 1.0150, 1.2587, 1.1569,\n",
       "                      1.2907, 1.0682, 1.0766, 1.0229, 1.5276, 1.0538, 1.2910, 1.1041, 1.0926,\n",
       "                      1.0011, 1.0612, 1.1573, 1.1036, 1.0309, 1.0178, 1.1831, 1.1869, 1.1159,\n",
       "                      0.9913, 1.2402, 1.1022, 1.2866, 1.1039, 1.0435, 1.3678, 1.0055, 1.0864,\n",
       "                      1.3696, 1.0363, 1.0860, 1.0645, 1.1420, 1.4791, 1.0633, 1.2459, 1.0234,\n",
       "                      1.0757, 1.0391, 1.2961, 1.1049, 1.0998, 1.0913, 1.2674, 1.1532, 1.0981,\n",
       "                      1.1731, 1.4588, 1.0724, 1.2617, 1.2777, 1.2773, 1.0826, 1.2916, 0.9876,\n",
       "                      1.0382, 1.2703, 1.0700, 1.3327, 1.0633, 1.3321, 1.1181, 1.2847, 1.0153,\n",
       "                      1.3911, 1.1077, 1.0058, 1.0759, 1.0676, 1.0161, 1.1979, 1.2694, 1.1185,\n",
       "                      1.0315, 1.2836, 1.0725, 1.2401, 1.3135, 1.1024, 1.0768, 1.2993, 1.1889,\n",
       "                      1.1437, 1.3191, 1.3357, 1.0475, 1.1445, 1.0783, 0.9807, 1.0795, 1.3786,\n",
       "                      1.0717, 1.1028, 1.0113, 1.1631, 1.0652, 1.0937, 1.0340, 1.2587, 1.1790,\n",
       "                      1.1525, 1.0185, 1.1045, 1.0566, 1.0646, 1.2037, 1.4843, 1.1518, 1.1229,\n",
       "                      1.3290, 1.2477, 1.0090, 1.0879, 1.2415, 1.1641, 1.1221, 1.3551, 1.5062,\n",
       "                      1.1363, 1.0737, 1.3951, 1.1338, 1.1346, 1.0690, 1.1999, 1.0416, 1.3096,\n",
       "                      1.1431, 1.0757, 1.1131, 1.1785, 1.2183, 1.4137, 1.0941, 1.1290, 1.0450,\n",
       "                      0.9785, 1.1356, 1.0318, 1.2108, 1.5008, 1.0214, 1.1657, 1.3875, 1.0314,\n",
       "                      1.2632, 1.1254, 1.0533, 1.0694, 1.1264, 1.3566, 1.0961, 0.9679, 1.2143,\n",
       "                      1.0003, 1.0572, 0.9897, 1.1213, 1.0190, 1.0901, 1.0905, 1.0556, 1.1765,\n",
       "                      1.1529, 1.5796, 1.0336, 1.5661, 1.0277, 1.0160, 1.2766, 0.9884])),\n",
       "             ('linear_relu_stack.1.num_batches_tracked', tensor(1)),\n",
       "             ('linear_relu_stack.Linear_1.weight',\n",
       "              tensor([[-0.0477,  0.0933, -0.0291,  ...,  0.0318,  0.0363, -0.0893],\n",
       "                      [-0.0398,  0.0394, -0.0126,  ...,  0.0906, -0.2367, -0.0901],\n",
       "                      [-0.0310,  0.0896, -0.0257,  ...,  0.0278, -0.0683,  0.0219],\n",
       "                      ...,\n",
       "                      [-0.0570, -0.0286, -0.0385,  ..., -0.0917, -0.0253,  0.0219],\n",
       "                      [ 0.0169, -0.1558,  0.0687,  ...,  0.0560,  0.0837,  0.0428],\n",
       "                      [ 0.0503,  0.1843, -0.0628,  ...,  0.1045, -0.1882, -0.0077]])),\n",
       "             ('linear_relu_stack.Linear_1.bias',\n",
       "              tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100])),\n",
       "             ('linear_relu_stack.BatchNorm_1.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1.])),\n",
       "             ('linear_relu_stack.BatchNorm_1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('linear_relu_stack.BatchNorm_1.running_mean',\n",
       "              tensor([ 1.5147e-01,  1.1869e-01,  9.6426e-02,  4.9622e-02, -2.1365e-01,\n",
       "                      -1.5440e-02,  5.1251e-02, -2.4910e-02,  1.3049e-01,  1.0530e-03,\n",
       "                       1.8741e-02,  4.1075e-02, -1.2303e-01,  1.5656e-01, -1.5665e-02,\n",
       "                      -3.3963e-02, -2.7858e-02,  1.1986e-01,  1.0280e-01,  6.4202e-02,\n",
       "                      -1.8336e-01,  1.5914e-01, -7.8135e-02, -5.2551e-02,  2.5477e-02,\n",
       "                       5.8169e-02,  6.3803e-02,  2.5275e-02, -3.4600e-03,  5.3525e-02,\n",
       "                      -7.5294e-02, -3.1249e-02, -2.4654e-02, -6.4183e-02,  1.8048e-02,\n",
       "                       6.4950e-03,  3.2345e-02,  1.0772e-01,  4.6262e-03, -1.7804e-02,\n",
       "                       1.0122e-01,  2.0516e-01,  5.6971e-02, -2.3681e-02,  1.3106e-01,\n",
       "                      -1.1325e-03, -8.2729e-02,  6.7407e-02, -3.5020e-02,  9.8335e-02,\n",
       "                       6.9331e-02, -2.3256e-02, -1.9122e-02,  6.6159e-02, -6.4977e-02,\n",
       "                       4.5683e-02,  1.6701e-01,  9.1978e-02,  3.7987e-02, -8.8218e-02,\n",
       "                      -5.7317e-02,  5.9556e-02,  7.7007e-02, -5.2736e-02, -2.5630e-02,\n",
       "                       7.7995e-02,  8.9267e-02, -6.5628e-03, -6.7262e-02,  1.1153e-01,\n",
       "                      -4.6747e-02,  1.2063e-01,  1.0874e-01,  1.3575e-02, -7.8514e-02,\n",
       "                      -3.6277e-02, -9.5646e-02, -3.5048e-02,  4.5463e-02, -1.0170e-01,\n",
       "                       1.1829e-01, -5.9469e-02,  7.8707e-02,  2.3432e-02, -1.1208e-01,\n",
       "                      -1.3937e-01,  9.6725e-02,  3.1764e-02, -7.6137e-02, -8.4038e-02,\n",
       "                       3.6576e-02,  4.7624e-02, -2.4008e-01,  1.4761e-01, -2.8839e-02,\n",
       "                      -2.7470e-02, -2.5521e-02,  1.6165e-01,  4.8435e-02,  7.8944e-02,\n",
       "                      -9.8681e-02, -1.3908e-01, -9.5847e-02, -6.4926e-02,  4.4183e-02,\n",
       "                       5.5869e-02, -1.5638e-01, -9.1034e-02, -2.2058e-02, -1.2935e-01,\n",
       "                      -4.7027e-03,  1.1293e-02,  1.1450e-01,  2.1155e-02, -1.9756e-02,\n",
       "                      -5.1992e-02,  1.0622e-02, -2.0313e-02, -1.4432e-01, -7.5126e-02,\n",
       "                      -9.4704e-03, -1.5449e-02,  7.3977e-02, -1.5884e-01,  6.0144e-02,\n",
       "                      -7.7250e-02, -3.8154e-02, -8.0403e-03, -7.5809e-02, -9.5953e-04,\n",
       "                       1.2588e-01,  1.3916e-01,  9.4686e-02,  9.2339e-02, -1.2683e-01,\n",
       "                      -2.2575e-02, -1.7050e-01, -1.0985e-01, -2.8435e-02,  8.1472e-03,\n",
       "                      -5.5525e-02, -4.4182e-02,  5.7286e-02,  2.8127e-02, -8.0316e-03,\n",
       "                       4.2171e-02,  7.1073e-02,  7.2391e-02,  4.3444e-03, -8.4458e-02,\n",
       "                       1.4313e-02, -7.8777e-02, -8.8462e-02,  5.1768e-02,  1.2771e-01,\n",
       "                       1.9586e-02,  1.1875e-01,  2.1404e-02, -1.0657e-01,  1.2046e-01,\n",
       "                      -1.0577e-01,  1.6908e-02, -1.1611e-01,  4.3274e-02, -3.6179e-02,\n",
       "                      -1.3742e-02,  1.5555e-01, -4.7653e-02, -3.5589e-02, -1.4142e-01,\n",
       "                       7.8283e-02,  1.3105e-01, -1.9760e-02,  5.5619e-02, -1.7788e-01,\n",
       "                       3.5850e-02,  1.4684e-02, -8.6867e-03,  8.1551e-02, -5.3358e-02,\n",
       "                       1.3355e-01,  1.3049e-01,  2.5259e-03,  4.6269e-02, -4.4583e-02,\n",
       "                      -1.1043e-01, -1.2755e-01, -3.9154e-02, -9.2400e-02, -6.6185e-02,\n",
       "                       1.4778e-01,  4.3906e-02, -6.9449e-02, -1.2649e-01,  1.7630e-02,\n",
       "                      -4.9017e-02,  4.4555e-02,  1.1543e-01, -4.8713e-03,  7.4001e-02,\n",
       "                      -1.1829e-02, -1.5564e-01,  6.0063e-02,  8.6875e-03, -4.3434e-02,\n",
       "                      -1.3844e-01, -9.6830e-02, -7.6826e-02,  6.4373e-02,  4.2203e-03,\n",
       "                      -1.4005e-02,  8.1423e-02,  3.8858e-02,  1.2698e-01, -4.0637e-03,\n",
       "                       2.2367e-02, -6.5378e-02,  1.0518e-01,  1.3584e-01,  8.1557e-02,\n",
       "                      -9.8483e-02, -1.2411e-01,  8.1779e-02,  8.1653e-02, -7.0932e-02,\n",
       "                       5.5810e-03, -1.9480e-02, -3.2007e-02, -4.4758e-02,  1.1518e-02,\n",
       "                      -3.6459e-02, -3.4565e-02, -1.6744e-02,  5.3855e-02,  1.9571e-02,\n",
       "                      -9.9654e-03, -5.8233e-02,  2.0090e-02,  4.0373e-02, -4.4327e-02,\n",
       "                      -3.7729e-02, -1.4767e-01,  3.0222e-02,  1.2909e-01,  9.2986e-02,\n",
       "                      -9.0038e-02, -2.5901e-02,  1.0644e-02, -7.2620e-02, -1.7266e-04,\n",
       "                       1.3669e-01, -1.5254e-01,  8.5092e-02, -2.2894e-02, -6.0108e-02,\n",
       "                      -1.3333e-02])),\n",
       "             ('linear_relu_stack.BatchNorm_1.running_var',\n",
       "              tensor([1.1545, 1.1625, 1.0938, 1.0974, 1.1435, 1.0969, 1.0817, 1.3975, 1.0904,\n",
       "                      1.0694, 1.2022, 1.0701, 1.0894, 1.0540, 1.1357, 1.0659, 1.1556, 1.0415,\n",
       "                      1.1044, 1.2416, 1.0895, 1.2179, 1.1616, 1.1586, 1.1275, 1.2001, 1.1155,\n",
       "                      1.1003, 1.0870, 1.0923, 1.1327, 1.0815, 1.1738, 1.0957, 1.0492, 1.0789,\n",
       "                      1.1807, 1.0761, 1.1390, 1.0238, 1.2802, 1.1475, 1.0687, 1.2264, 1.1316,\n",
       "                      1.1686, 1.0869, 1.0261, 1.0500, 1.0846, 1.1175, 1.2162, 1.2086, 1.1500,\n",
       "                      1.0759, 1.0888, 1.0691, 1.1003, 1.1541, 1.1619, 1.2839, 1.0927, 1.1029,\n",
       "                      1.1103, 1.0602, 1.0320, 1.2016, 1.0602, 1.0971, 1.1090, 1.1048, 1.1903,\n",
       "                      1.0318, 1.2026, 1.1162, 1.1416, 1.1757, 1.1446, 1.1482, 1.1302, 1.0142,\n",
       "                      1.0438, 1.1158, 1.0891, 1.2245, 1.0678, 1.1408, 1.0835, 1.0843, 1.2126,\n",
       "                      1.1700, 1.0974, 1.0644, 1.3230, 1.0764, 1.1763, 1.0795, 1.0439, 1.0084,\n",
       "                      1.1190, 1.1248, 1.1215, 1.1005, 1.0819, 1.0471, 1.0755, 1.0678, 1.1155,\n",
       "                      1.0753, 1.1176, 1.2010, 1.0619, 1.0462, 1.0825, 1.2337, 1.1303, 1.2676,\n",
       "                      1.1083, 1.1260, 1.0875, 1.0499, 1.1935, 1.2047, 1.2395, 1.0968, 1.1182,\n",
       "                      1.0855, 1.0805, 1.2197, 1.2035, 1.1423, 1.2372, 1.0510, 1.0924, 1.0193,\n",
       "                      1.1016, 1.1205, 1.0167, 1.1722, 1.0899, 1.1007, 1.1031, 1.1415, 1.0731,\n",
       "                      1.0843, 1.1453, 1.0928, 1.1251, 1.1655, 1.2685, 1.0925, 1.1729, 1.0655,\n",
       "                      1.0913, 1.0518, 1.2006, 1.0462, 1.0868, 1.0154, 1.0619, 1.1821, 1.0882,\n",
       "                      1.1770, 1.0163, 1.1746, 1.1413, 1.1196, 1.0806, 1.3570, 1.2761, 1.0400,\n",
       "                      1.1680, 1.2358, 1.1266, 1.0620, 1.1620, 1.1661, 1.0831, 1.0899, 1.2754,\n",
       "                      1.0619, 1.1488, 1.0595, 1.1511, 1.1136, 1.1173, 1.2598, 1.0819, 1.1272,\n",
       "                      1.2147, 1.2173, 1.1430, 1.0605, 1.0532, 1.4309, 1.2442, 1.1129, 1.0551,\n",
       "                      1.0570, 1.1634, 1.0504, 1.1680, 1.2466, 1.1767, 1.1844, 1.2141, 1.0450,\n",
       "                      1.1257, 1.1354, 1.0451, 1.1741, 1.1158, 1.0848, 1.1366, 1.0685, 1.1524,\n",
       "                      1.0905, 1.0824, 1.0974, 1.2075, 1.0296, 1.1248, 1.0859, 1.0888, 1.1155,\n",
       "                      1.1066, 1.0573, 1.0369, 1.1097, 1.1171, 1.2739, 1.1361, 1.3664, 1.0987,\n",
       "                      1.0443, 1.1968, 1.0417, 1.0970, 1.1165, 1.1366, 1.1676, 1.0867, 1.1322,\n",
       "                      1.1383, 1.1398, 1.1089, 1.0687, 1.1480, 1.0503, 1.0656, 1.0945, 1.0792,\n",
       "                      1.0931, 1.2599, 1.1369, 1.1306])),\n",
       "             ('linear_relu_stack.BatchNorm_1.num_batches_tracked', tensor(1)),\n",
       "             ('linear_relu_stack.Linear_2.weight',\n",
       "              tensor([[ 0.3858, -0.0944,  0.2352,  ...,  0.1415,  0.2814,  0.1611],\n",
       "                      [ 0.1585,  0.1439, -0.0221,  ...,  0.0219, -0.1279, -0.0919],\n",
       "                      [ 0.0453,  0.0132, -0.0813,  ..., -0.1256, -0.0664,  0.0546],\n",
       "                      ...,\n",
       "                      [ 0.2093, -0.0738, -0.1610,  ...,  0.0868, -0.0139,  0.0708],\n",
       "                      [-0.0186, -0.0103,  0.2909,  ..., -0.1275,  0.0601,  0.0169],\n",
       "                      [ 0.1031, -0.0317, -0.1600,  ..., -0.0611, -0.0392,  0.0247]])),\n",
       "             ('linear_relu_stack.Linear_2.bias',\n",
       "              tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100, 0.0100])),\n",
       "             ('linear_relu_stack.BatchNorm_2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('linear_relu_stack.BatchNorm_2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('linear_relu_stack.BatchNorm_2.running_mean',\n",
       "              tensor([ 0.1176, -0.0859, -0.0609, -0.0188,  0.0344,  0.1203, -0.0557, -0.0284,\n",
       "                      -0.0776,  0.0486, -0.0927,  0.0762, -0.0690,  0.1688, -0.0644,  0.0262,\n",
       "                      -0.0049, -0.0783,  0.0277,  0.0337, -0.0121,  0.0564,  0.0736,  0.0563,\n",
       "                       0.0061, -0.0949, -0.0193,  0.0577, -0.0103, -0.0552,  0.1470, -0.1470,\n",
       "                      -0.0756,  0.2105, -0.0644, -0.0646, -0.0326,  0.0619, -0.0047,  0.1393,\n",
       "                      -0.0326,  0.0939, -0.0129, -0.0035, -0.0116,  0.0912,  0.1054,  0.0348,\n",
       "                       0.0004,  0.0037,  0.0453,  0.0944,  0.0651, -0.0098,  0.0323,  0.1792,\n",
       "                       0.1275, -0.0291, -0.0789,  0.0088, -0.1506,  0.1244, -0.0260,  0.1277,\n",
       "                      -0.1764, -0.0609,  0.0553,  0.0054,  0.0647,  0.0171, -0.1015,  0.0383,\n",
       "                      -0.0476,  0.0621, -0.0196,  0.1441,  0.0194, -0.0408, -0.0260,  0.0166,\n",
       "                       0.0050, -0.0558, -0.0325, -0.0014,  0.0108,  0.1087, -0.0387, -0.1183,\n",
       "                      -0.0316,  0.1063,  0.0266, -0.0727, -0.0987, -0.0816,  0.0911,  0.0278,\n",
       "                       0.0037,  0.1329,  0.0003, -0.0507,  0.1014, -0.1353, -0.0566, -0.1605,\n",
       "                      -0.0735, -0.0239, -0.1069,  0.0029, -0.0402,  0.0044,  0.0424,  0.1319,\n",
       "                      -0.1114,  0.0255, -0.1754, -0.2602,  0.0908, -0.0212, -0.1539,  0.1011,\n",
       "                      -0.1026, -0.0036,  0.1397,  0.0816,  0.1632, -0.0484,  0.0993,  0.1376])),\n",
       "             ('linear_relu_stack.BatchNorm_2.running_var',\n",
       "              tensor([1.1613, 1.1448, 1.1124, 1.1034, 1.1488, 1.1086, 1.1023, 1.1093, 1.1751,\n",
       "                      1.1030, 1.1090, 1.1849, 1.0919, 1.0979, 1.1510, 1.1103, 1.0828, 1.1530,\n",
       "                      1.0417, 1.1294, 1.1258, 1.1354, 1.0791, 1.1753, 1.1539, 1.1769, 1.0903,\n",
       "                      1.0570, 1.1396, 1.0869, 1.0661, 1.1776, 1.0556, 1.0924, 1.0703, 1.0988,\n",
       "                      1.1380, 1.1430, 1.1084, 1.0909, 1.0936, 1.1270, 1.1630, 1.0641, 1.1516,\n",
       "                      1.1507, 1.1306, 1.0996, 1.1341, 1.0901, 1.0714, 1.1424, 1.0956, 1.0759,\n",
       "                      1.1062, 1.0561, 1.0911, 1.1485, 1.1392, 1.0951, 1.1493, 1.1085, 1.0747,\n",
       "                      1.0605, 1.1110, 1.1309, 1.2020, 1.1031, 1.0228, 1.0811, 1.1580, 1.2121,\n",
       "                      1.0818, 1.0493, 1.0708, 1.1744, 1.1726, 1.0994, 1.0845, 1.1909, 1.1469,\n",
       "                      1.1117, 1.0887, 1.0398, 1.1616, 1.1326, 0.9925, 1.0998, 1.1750, 1.1947,\n",
       "                      1.1005, 1.1015, 1.1065, 1.1202, 1.1429, 1.0729, 1.1101, 1.1341, 1.1083,\n",
       "                      1.1106, 1.1384, 1.1077, 1.1634, 1.1739, 1.0979, 1.1070, 1.1033, 1.1730,\n",
       "                      1.1676, 1.1696, 1.0718, 1.1447, 1.1656, 1.1296, 1.2060, 1.1349, 1.1557,\n",
       "                      1.0763, 1.0747, 1.1906, 1.0355, 1.2335, 1.1021, 1.0761, 1.0621, 1.0816,\n",
       "                      1.2367, 1.1742])),\n",
       "             ('linear_relu_stack.BatchNorm_2.num_batches_tracked', tensor(1)),\n",
       "             ('linear_relu_stack.Output_Layer.weight',\n",
       "              tensor([[ 0.6793, -0.5863, -0.1370,  ...,  0.2893,  0.6256,  0.1686],\n",
       "                      [ 0.2119, -0.0911, -0.4682,  ...,  0.5681,  0.3806,  0.5708],\n",
       "                      [ 0.3817,  0.0098, -0.0434,  ..., -0.0730, -0.3799, -0.1168],\n",
       "                      ...,\n",
       "                      [ 0.3345, -0.7971, -0.3029,  ...,  0.9510,  0.0048,  0.2641],\n",
       "                      [ 0.1896,  0.0060, -0.1834,  ..., -0.1593, -0.0075,  0.4111],\n",
       "                      [-0.5616,  0.7565, -0.1957,  ..., -0.3139,  1.1596, -1.1187]])),\n",
       "             ('linear_relu_stack.Output_Layer.bias',\n",
       "              tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
       "                      0.0100]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict() # 获取模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11b8d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "class TensorboardLogger:\n",
    "    \"\"\"\n",
    "    Tensorboard日志记录类：记录训练过程中的损失和准确率\n",
    "    \n",
    "    参数:\n",
    "        log_dir: 日志保存目录\n",
    "    \"\"\"\n",
    "    def __init__(self,log_dir='tensorboard_log'):\n",
    "        import os\n",
    "        # 确保日志目录存在\n",
    "        if not os.path.exists(log_dir):\n",
    "            os.mkdir(log_dir)\n",
    "        \n",
    "        self.writer=SummaryWriter(log_dir) # 实例化SummaryWriter, log_dir是log存放路径，flush_secs是每隔多少秒写入磁盘\n",
    "\n",
    "    def log_training(self,epoch,train_loss,train_acc):\n",
    "        \"\"\"\n",
    "        记录训练数据\n",
    "        \n",
    "        参数:\n",
    "            epoch: 当前训练轮数\n",
    "            train_loss: 训练损失\n",
    "            train_acc: 训练准确率\n",
    "        \"\"\"\n",
    "        self.writer.add_scalar('train_loss',train_loss,epoch)\n",
    "        self.writer.add_scalar('train_acc',train_acc,epoch)\n",
    "    \n",
    "    def log_validation(self,epoch,val_loss,val_acc):\n",
    "        \"\"\"\n",
    "        记录验证数据\n",
    "        \n",
    "        参数:\n",
    "            epoch: 当前训练轮数\n",
    "            val_loss: 验证损失\n",
    "            val_acc: 验证准确率\n",
    "        \"\"\"\n",
    "        self.writer.add_scalar('val_loss',val_loss,epoch)\n",
    "        self.writer.add_scalar('val_acc',val_acc,epoch)\n",
    "    \n",
    "    def log_lr(self,epoch,lr):\n",
    "        \"\"\"\n",
    "        记录学习率\n",
    "        \n",
    "        参数:\n",
    "            epoch: 当前训练轮数\n",
    "            lr: 学习率\n",
    "        \"\"\"\n",
    "        self.writer.add_scalar('lr',lr,epoch)\n",
    "    \n",
    "    def log_model_graph(self,model,images):\n",
    "        \"\"\"\n",
    "        记录模型结构图\n",
    "        \n",
    "        参数:\n",
    "            model: 模型\n",
    "            images: 输入图像样本\n",
    "        \"\"\" \n",
    "        self.writer.add_graph(model,images)\n",
    "    \n",
    "    def closs(self):\n",
    "        \"\"\"\n",
    "        关闭Tensorboard写入器\n",
    "        \"\"\"\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c1f9a",
   "metadata": {},
   "source": [
    "# 设置交叉熵损失函数，SGD优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38a2c883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "损失函数: CrossEntropyLoss()\n",
      "优化器: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=NeuralNetwork()\n",
    "# 定义损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss() # 交叉熵损失函数，适用于多分类问题，里边会做softmax，还有会把0-9标签转换成one-hot编码\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01,momentum=0.9) # SGD优化器，学习率为0.01，动量为0.9\n",
    "print(\"损失函数:\",loss_fn)\n",
    "print(\"优化器:\",optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83207833",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model =NeuralNetwork(dropout_rate=0.3, initial_size=512)\n",
    "model.to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34ec2d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前设备: cuda:0\n",
      "训练开始，共43000步\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f7d353538940b489b897c1930869e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "早停触发! 最佳验证准确率: 88.8200\n",
      "早停: 已有5轮验证损失没有改善！\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# device='cpu'\n",
    "print(f\"当前设备: {device}\")\n",
    "early_stopping=EarlyStopping(patience=5, delta=0.001)\n",
    "model_saver=ModelSaver(save_dir='model_weights', save_best_only=True)\n",
    "tensorboard_logger=TensorboardLogger(log_dir='logs')\n",
    "\n",
    "model, history = train_classification_model(model, train_loader, val_loader, loss_fn, optimizer, device, num_epochs=50, early_stopping=early_stopping, model_saver=model_saver, tensorboard_logger=tensorboard_logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82473955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 16.899724095153807, 'acc': 10.7, 'step': 0},\n",
       " {'loss': 0.48546032328605654, 'acc': 83.36, 'step': 500},\n",
       " {'loss': 0.4308036099910736, 'acc': 84.14, 'step': 1000},\n",
       " {'loss': 0.38646918687820436, 'acc': 86.06, 'step': 1500},\n",
       " {'loss': 0.3876049201965332, 'acc': 86.36, 'step': 2000},\n",
       " {'loss': 0.37634023184776305, 'acc': 85.94, 'step': 2500},\n",
       " {'loss': 0.36797951455116273, 'acc': 86.72, 'step': 3000},\n",
       " {'loss': 0.3573906052350998, 'acc': 87.02, 'step': 3500},\n",
       " {'loss': 0.35182093331813813, 'acc': 87.3, 'step': 4000},\n",
       " {'loss': 0.34468238751888275, 'acc': 87.72, 'step': 4500},\n",
       " {'loss': 0.3457391823887825, 'acc': 87.56, 'step': 5000},\n",
       " {'loss': 0.33512009100914003, 'acc': 88.12, 'step': 5500},\n",
       " {'loss': 0.32471050559282305, 'acc': 88.24, 'step': 6000},\n",
       " {'loss': 0.3493187413454056, 'acc': 87.44, 'step': 6500},\n",
       " {'loss': 0.3209104345560074, 'acc': 88.34, 'step': 7000},\n",
       " {'loss': 0.31459654475450516, 'acc': 88.82, 'step': 7500},\n",
       " {'loss': 0.32045904378890994, 'acc': 88.24, 'step': 8000},\n",
       " {'loss': 0.31949230201244355, 'acc': 88.58, 'step': 8500},\n",
       " {'loss': 0.3225365833759308, 'acc': 88.1, 'step': 9000},\n",
       " {'loss': 0.31512735117673873, 'acc': 88.48, 'step': 9500}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['val'][-1000:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8106d05d",
   "metadata": {},
   "source": [
    "# 绘制损失曲线和准确率曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "add253a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(history,sample_step=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16092a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88.87, 0.31062227255105973)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy=evaluate_model(model,test_loader,device,loss_fn)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8efe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
